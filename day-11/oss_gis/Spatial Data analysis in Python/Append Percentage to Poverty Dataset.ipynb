{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Append Percentage to Poverty Dataset\n",
      "\n",
      "## Step 1. Imports\n",
      "\n",
      "The data from the census always comes in the form of raw counts.  Since different census tracts around the country have vastly different numbers of people, we want to normalize to something more reasonable, say percentages. \n",
      "\n",
      "This example goes from the raw numbers: \"Number of households receiving food stamps or cash assistance\" to \"Percentage of households receiving food stamps or cash assistance\" collected by US Census Tract (2010). We also bin the resulting percentages into deciles to make 10 classes for visualization."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas # data analysis\n",
      "import sh\n",
      "import sqlite3 \n",
      "import numpy as np\n",
      "\n",
      "pandas.set_option('display.max_columns', 20)\n",
      "pandas.set_option('display.max_rows', 25)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Generally, convention is that you do your imports at the top of the file.  This is not strictly necessary, but it helps other people look at your code and understand what broad tasks you want to perform.\n",
      "\n",
      "* [__Pandas__ is a library for dealing with tabular data](http://pandas.pydata.org). It's like Excel macros for Python. You can load Excel spreadsheets, data from relational databases, and and flat files. You can do selection of columns, filtering of rows, complex statistical analysis. You can even map R routines to datasets.\n",
      "\n",
      "* [__sh__ is a library for performing shell commands in Python](http://amoffat.github.io/sh/).\n",
      "* __sqlite3__ comes with python and provides access to SQLite database files\n",
      "* [__numpy__ is a highly performant library for numerical computation](http://www.numpy.org). Numpy is written in Fortran and C.  It takes advantage of HPC libraries and provides native, C-level performance in a high-level package.\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Step 2. Data selection\n",
      "\n",
      "First thing to do is create a dataset that supports SQL queries.  Actually, OGR in general supports SQL, but switching to SQLite gives us better performance:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sh.ogr2ogr(\n",
      "    '-f', 'SQLite', \n",
      "    '-overwrite', \n",
      "    '-dsco', 'SPATIALITE=YES',\n",
      "    '-explodecollections',\n",
      "    'foodstamps_nc_tract.sqlite', \n",
      "    'foodstamps_nc_tract.shp',\n",
      ")   "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 26,
       "text": []
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we need to get some data to manipulate.  The full tract data contains plenty of data we don't actually need for computation, so we use an SQL query to narrow the size of the dataset.  Pandas gives us a simple way to get that data, view it in the Notebook, and then manipulate it as we'll see below.\n",
      "\n",
      "If we open the metadata spreadsheet in Excel (acs_metadata.csv), we can see two variables that can help us.  There are more, but let's keep things simple for now.  We want to know who has been on public assistance whether cash or WIC/SNAP.  The ACS gives us household level information, so the numbers above should be considered household numbers.  They are imputed -- that is, inexact -- but that's fine for our purposes, since we're doing public health and working with a \"broad brush\".  The two variables above are Total Household Count and Total Households receiving WIC/SNAP or Public Assistance.  \n",
      "\n",
      "It's important to use the household count that goes with the variable you are analyzing, as these can (although usually aren't) be different because they are modeled data.\n",
      "\n",
      "Pandas gives us a __DataFrame__.  A DataFrame is analogous to a single sheet in Excel or a single table in an SQL database.  It has an index column (the far left, seen above) and columns of data series.  Data in Pandas is stored in column major order, so computations across entire columns are the fastest.  \n",
      "\n",
      "Pandas gives you a number of iterators that can be used to select data differently, but it also defines a convenient set of operators that make it simple to act on columns the way we might do in mathematical notation."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "db = sqlite3.connect('foodstamps_nc_tract.sqlite')\n",
      "df = pandas.read_sql('select OGC_FID, b19058e2, b19058e1 from foodstamps_nc_tract', db)\n",
      "df # print the dataframe in the browser"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>OGC_FID</th>\n",
        "      <th>b19058e2</th>\n",
        "      <th>b19058e1</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0   </th>\n",
        "      <td>    1</td>\n",
        "      <td> 231</td>\n",
        "      <td> 1260</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1   </th>\n",
        "      <td>    2</td>\n",
        "      <td> 215</td>\n",
        "      <td> 1437</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2   </th>\n",
        "      <td>    3</td>\n",
        "      <td> 359</td>\n",
        "      <td> 1922</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3   </th>\n",
        "      <td>    4</td>\n",
        "      <td> 253</td>\n",
        "      <td> 2082</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4   </th>\n",
        "      <td>    5</td>\n",
        "      <td> 412</td>\n",
        "      <td> 2853</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5   </th>\n",
        "      <td>    6</td>\n",
        "      <td> 137</td>\n",
        "      <td> 1336</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6   </th>\n",
        "      <td>    7</td>\n",
        "      <td>  10</td>\n",
        "      <td>  692</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7   </th>\n",
        "      <td>    8</td>\n",
        "      <td>  91</td>\n",
        "      <td> 1394</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8   </th>\n",
        "      <td>    9</td>\n",
        "      <td>  61</td>\n",
        "      <td>  546</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9   </th>\n",
        "      <td>   10</td>\n",
        "      <td> 142</td>\n",
        "      <td> 1306</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>10  </th>\n",
        "      <td>   11</td>\n",
        "      <td>  69</td>\n",
        "      <td> 1564</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11  </th>\n",
        "      <td>   12</td>\n",
        "      <td> 446</td>\n",
        "      <td> 1931</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>...</th>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2187</th>\n",
        "      <td> 2188</td>\n",
        "      <td>   0</td>\n",
        "      <td>    0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2188</th>\n",
        "      <td> 2189</td>\n",
        "      <td> 406</td>\n",
        "      <td> 1051</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2189</th>\n",
        "      <td> 2190</td>\n",
        "      <td> 110</td>\n",
        "      <td> 1698</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2190</th>\n",
        "      <td> 2191</td>\n",
        "      <td> 444</td>\n",
        "      <td>  954</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2191</th>\n",
        "      <td> 2192</td>\n",
        "      <td> 221</td>\n",
        "      <td> 2116</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2192</th>\n",
        "      <td> 2193</td>\n",
        "      <td> 162</td>\n",
        "      <td> 1403</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2193</th>\n",
        "      <td> 2194</td>\n",
        "      <td>   0</td>\n",
        "      <td>    0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2194</th>\n",
        "      <td> 2195</td>\n",
        "      <td> 101</td>\n",
        "      <td> 1300</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2195</th>\n",
        "      <td> 2196</td>\n",
        "      <td> 101</td>\n",
        "      <td> 1300</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2196</th>\n",
        "      <td> 2197</td>\n",
        "      <td> 241</td>\n",
        "      <td> 1169</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2197</th>\n",
        "      <td> 2198</td>\n",
        "      <td> 162</td>\n",
        "      <td> 1684</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2198</th>\n",
        "      <td> 2199</td>\n",
        "      <td> 168</td>\n",
        "      <td> 1323</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>2199 rows \u00d7 3 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 27,
       "text": [
        "      OGC_FID  b19058e2  b19058e1\n",
        "0           1       231      1260\n",
        "1           2       215      1437\n",
        "2           3       359      1922\n",
        "3           4       253      2082\n",
        "4           5       412      2853\n",
        "5           6       137      1336\n",
        "6           7        10       692\n",
        "7           8        91      1394\n",
        "8           9        61       546\n",
        "9          10       142      1306\n",
        "10         11        69      1564\n",
        "11         12       446      1931\n",
        "...       ...       ...       ...\n",
        "2187     2188         0         0\n",
        "2188     2189       406      1051\n",
        "2189     2190       110      1698\n",
        "2190     2191       444       954\n",
        "2191     2192       221      2116\n",
        "2192     2193       162      1403\n",
        "2193     2194         0         0\n",
        "2194     2195       101      1300\n",
        "2195     2196       101      1300\n",
        "2196     2197       241      1169\n",
        "2197     2198       162      1684\n",
        "2198     2199       168      1323\n",
        "\n",
        "[2199 rows x 3 columns]"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Step 3. Analysis"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pct_poverty = (df['b19058e2'] / (df['b19058e1']+1) * 100.0).round()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>OGC_FID</th>\n",
        "      <th>pct_poverty</th>\n",
        "      <th>poverty_class</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>count</th>\n",
        "      <td> 2199.000000</td>\n",
        "      <td> 2199.000000</td>\n",
        "      <td> 2199.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>mean</th>\n",
        "      <td> 1100.000000</td>\n",
        "      <td>   13.685312</td>\n",
        "      <td>    7.309231</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>std</th>\n",
        "      <td>  634.940942</td>\n",
        "      <td>   10.679256</td>\n",
        "      <td>    0.988957</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>min</th>\n",
        "      <td>    1.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    5.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>25%</th>\n",
        "      <td>  550.500000</td>\n",
        "      <td>    6.000000</td>\n",
        "      <td>    7.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>50%</th>\n",
        "      <td> 1100.000000</td>\n",
        "      <td>   12.000000</td>\n",
        "      <td>    7.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>75%</th>\n",
        "      <td> 1649.500000</td>\n",
        "      <td>   19.000000</td>\n",
        "      <td>    8.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>max</th>\n",
        "      <td> 2199.000000</td>\n",
        "      <td>   77.000000</td>\n",
        "      <td>   10.000000</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 28,
       "text": [
        "           OGC_FID  pct_poverty  poverty_class\n",
        "count  2199.000000  2199.000000    2199.000000\n",
        "mean   1100.000000    13.685312       7.309231\n",
        "std     634.940942    10.679256       0.988957\n",
        "min       1.000000     0.000000       5.000000\n",
        "25%     550.500000     6.000000       7.000000\n",
        "50%    1100.000000    12.000000       7.000000\n",
        "75%    1649.500000    19.000000       8.000000\n",
        "max    2199.000000    77.000000      10.000000"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First, let's get the percentage of people receiving assistance.  You'll recognize the very straightforward computation above. The division is done row-wise, so items with the same row are divided between columns: `a[0] / b[0]`, `a[1] / b[1]` and so on. We round off the data so it can be displayed later without clutter, and because it doesn't affect our data too much.  \n",
      "\n",
      "We are cheating here slightly - it so happens that the occasional census tract has no people in it.  To correct for this and avoid getting off-by-one errors, we add one to the demoninator.  This assures that there's always one person in the tract.  This isn't particularly statistically sound, but this is an example analysis.\n",
      "\n",
      "Next we will classify tracts and bin them accordingly.  What's the easiest way to bin data?  A histogram.  We divide the data into deciles with `np.histogram` and then we use the resulting bin boundaries with `np.digitize` to code the data.  We then store these codes in a new __Series__, which is one column of a __DataFrame__:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "poverty_classes = pandas.Series(np.digitize(df2['pct_poverty'], np.histogram(df2['pct_poverty'])[0]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "What we have just done here is created a new series.  `np` is our shorthand for Numpy in the imports section.  Histogram returns two items: the bin boundaries and the bin counts as a tuple:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.histogram(df2['pct_poverty'])[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we create a new table from the results.  We need to include the primary key from the original data in that table, so we can map our derived data to the original data.  The primary key in OGR datasets is always `OGC_FID`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df2 = pandas.DataFrame({\n",
      "    'OGC_FID' : df['OGC_FID'], \n",
      "    'pct_poverty' : pct_poverty,\n",
      "    'poverty_class' : poverty_classes\n",
      "})\n",
      "df2.describe()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Step 4. Write the data\n",
      "\n",
      "In this section, we write a new table to our original file, calling it `poverty`. We then prepare for later analysis of the data we intend to do by changing the projection to a projection that can support a meaningful distance calculation and writing it out to the \"lowest common demoninator\" format, ESRI Shapefile."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pandas.io.sql.to_sql(df2, 'poverty', db, if_exists='replace')\n",
      "db.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Pandas allows us to write data out in many formats: proprietary, Excel, SQL, CSV, HDF5, and NetCDF to name a few.  However in this case we just want to take the data and write it right back out to the original dataset.  We use the original database connection we established at the beginning of the exercise and tell the script to replace the table if it already exists.\n",
      "\n",
      "We now have an SQLite database with our original data and a new table.  But it's in a lat/lon projection.  We need a projection that will support our later efforts to understand the distance people have to travel to get to a Farmers Market.  For this I'm choosing Google's projection, EPSG:3857, because it is a good general projection for North America and supports web maps well."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sh.ogr2ogr(\n",
      "    '-f', 'ESRI Shapefile', \n",
      "    '-overwrite',  \n",
      "    '-t_srs', 'epsg:3857',\n",
      "    'foodstamps_nc_pct.shp',\n",
      "    'foodstamps_nc_tract.sqlite',\n",
      "    '-sql', 'select a.*, b.pct_poverty, b.poverty_class from foodstamps_nc_tract as a, poverty as b where a.OGC_FID=b.OGC_FID'\n",
      ")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 30,
       "text": []
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We take the original file, transform it, and turn it into a Shapefile.  The data we want is \"all of it\" though, and Shapefiles only support a single table/layer, and that makes it easier for us to work with anyway.  To support this we use an SQL statement to select the data as a single table, joining the two tables on the primary key, `OGC_FID` we used earlier.\n",
      "\n",
      "[Now on to the next lesson...](http://127.0.0.1:8888/0de91ef4-2324-4e16-bf38-e6c34ebccc53)"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}