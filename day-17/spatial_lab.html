<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title></title>
  <style type="text/css">code{white-space: pre;}</style>
  <style type="text/css">
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; }
code > span.dt { color: #902000; }
code > span.dv { color: #40a070; }
code > span.bn { color: #40a070; }
code > span.fl { color: #40a070; }
code > span.ch { color: #4070a0; }
code > span.st { color: #4070a0; }
code > span.co { color: #60a0b0; font-style: italic; }
code > span.ot { color: #007020; }
code > span.al { color: #ff0000; font-weight: bold; }
code > span.fu { color: #06287e; }
code > span.er { color: #ff0000; font-weight: bold; }
  </style>
  <link href="data:text/css,body%2C%20td%20%7B%0A%20%20%20font%2Dfamily%3A%20sans%2Dserif%3B%0A%20%20%20background%2Dcolor%3A%20white%3B%0A%20%20%20font%2Dsize%3A%2013px%3B%0A%7D%0A%0Abody%20%7B%0A%20%20max%2Dwidth%3A%20800px%3B%0A%20%20margin%3A%20auto%3B%0A%20%20padding%3A%201em%3B%0A%20%20line%2Dheight%3A%2020px%3B%0A%7D%0A%0Att%2C%20code%2C%20pre%20%7B%0A%20%20%20font%2Dfamily%3A%20%27DejaVu%20Sans%20Mono%27%2C%20%27Droid%20Sans%20Mono%27%2C%20%27Lucida%20Console%27%2C%20Consolas%2C%20Monaco%2C%20monospace%3B%0A%7D%0A%0Ah1%20%7B%0A%20%20%20font%2Dsize%3A2%2E2em%3B%0A%7D%0A%0Ah2%20%7B%0A%20%20%20font%2Dsize%3A1%2E8em%3B%0A%7D%0A%0Ah3%20%7B%0A%20%20%20font%2Dsize%3A1%2E4em%3B%0A%7D%0A%0Ah4%20%7B%0A%20%20%20font%2Dsize%3A1%2E0em%3B%0A%7D%0A%0Ah5%20%7B%0A%20%20%20font%2Dsize%3A0%2E9em%3B%0A%7D%0A%0Ah6%20%7B%0A%20%20%20font%2Dsize%3A0%2E8em%3B%0A%7D%0A%0Aa%3Avisited%20%7B%0A%20%20%20color%3A%20rgb%2850%25%2C%200%25%2C%2050%25%29%3B%0A%7D%0A%0Apre%2C%20img%20%7B%0A%20%20max%2Dwidth%3A%20100%25%3B%0A%7D%0A%0Apre%20code%20%7B%0A%20%20%20display%3A%20block%3B%20padding%3A%200%2E5em%3B%0A%7D%0A%0Acode%20%7B%0A%20%20font%2Dsize%3A%2092%25%3B%0A%20%20border%3A%201px%20solid%20%23ccc%3B%0A%7D%0A%0Acode%5Bclass%5D%20%7B%0A%20%20background%2Dcolor%3A%20%23F8F8F8%3B%0A%7D%0A%0Atable%2C%20td%2C%20th%20%7B%0A%20%20border%3A%20none%3B%0A%7D%0A%0Ablockquote%20%7B%0A%20%20%20color%3A%23666666%3B%0A%20%20%20margin%3A0%3B%0A%20%20%20padding%2Dleft%3A%201em%3B%0A%20%20%20border%2Dleft%3A%200%2E5em%20%23EEE%20solid%3B%0A%7D%0A%0Ahr%20%7B%0A%20%20%20height%3A%200px%3B%0A%20%20%20border%2Dbottom%3A%20none%3B%0A%20%20%20border%2Dtop%2Dwidth%3A%20thin%3B%0A%20%20%20border%2Dtop%2Dstyle%3A%20dotted%3B%0A%20%20%20border%2Dtop%2Dcolor%3A%20%23999999%3B%0A%7D%0A%0A%40media%20print%20%7B%0A%20%20%20%2A%20%7B%0A%20%20%20%20%20%20background%3A%20transparent%20%21important%3B%0A%20%20%20%20%20%20color%3A%20black%20%21important%3B%0A%20%20%20%20%20%20filter%3Anone%20%21important%3B%0A%20%20%20%20%20%20%2Dms%2Dfilter%3A%20none%20%21important%3B%0A%20%20%20%7D%0A%0A%20%20%20body%20%7B%0A%20%20%20%20%20%20font%2Dsize%3A12pt%3B%0A%20%20%20%20%20%20max%2Dwidth%3A100%25%3B%0A%20%20%20%7D%0A%0A%20%20%20a%2C%20a%3Avisited%20%7B%0A%20%20%20%20%20%20text%2Ddecoration%3A%20underline%3B%0A%20%20%20%7D%0A%0A%20%20%20hr%20%7B%0A%20%20%20%20%20%20visibility%3A%20hidden%3B%0A%20%20%20%20%20%20page%2Dbreak%2Dbefore%3A%20always%3B%0A%20%20%20%7D%0A%0A%20%20%20pre%2C%20blockquote%20%7B%0A%20%20%20%20%20%20padding%2Dright%3A%201em%3B%0A%20%20%20%20%20%20page%2Dbreak%2Dinside%3A%20avoid%3B%0A%20%20%20%7D%0A%0A%20%20%20tr%2C%20img%20%7B%0A%20%20%20%20%20%20page%2Dbreak%2Dinside%3A%20avoid%3B%0A%20%20%20%7D%0A%0A%20%20%20img%20%7B%0A%20%20%20%20%20%20max%2Dwidth%3A%20100%25%20%21important%3B%0A%20%20%20%7D%0A%0A%20%20%20%40page%20%3Aleft%20%7B%0A%20%20%20%20%20%20margin%3A%2015mm%2020mm%2015mm%2010mm%3B%0A%20%20%20%7D%0A%0A%20%20%20%40page%20%3Aright%20%7B%0A%20%20%20%20%20%20margin%3A%2015mm%2010mm%2015mm%2020mm%3B%0A%20%20%20%7D%0A%0A%20%20%20p%2C%20h2%2C%20h3%20%7B%0A%20%20%20%20%20%20orphans%3A%203%3B%20widows%3A%203%3B%0A%20%20%20%7D%0A%0A%20%20%20h2%2C%20h3%20%7B%0A%20%20%20%20%20%20page%2Dbreak%2Dafter%3A%20avoid%3B%0A%20%20%20%7D%0A%7D%0A" rel="stylesheet" type="text/css" />
  <script type="text/javascript">/**/
  /* 
  March 19, 2004 MathHTML (c) Peter Jipsen http://www.chapman.edu/~jipsen
  Released under the GNU General Public License version 2 or later.
  See the GNU General Public License (at http://www.gnu.org/copyleft/gpl.html)
  for more details.
  */
  
  function convertMath(node) {// for Gecko
    if (node.nodeType==1) {
      var newnode = 
        document.createElementNS("http://www.w3.org/1998/Math/MathML",
          node.nodeName.toLowerCase());
      for(var i=0; i < node.attributes.length; i++)
        newnode.setAttribute(node.attributes[i].nodeName,
          node.attributes[i].nodeValue);
      for (var i=0; i<node.childNodes.length; i++) {
        var st = node.childNodes[i].nodeValue;
        if (st==null || st.slice(0,1)!=" " && st.slice(0,1)!="\n") 
          newnode.appendChild(convertMath(node.childNodes[i]));
      }
      return newnode;
    }
    else return node;
  }
  
  function convert() {
    var mmlnode = document.getElementsByTagName("math");
    var st,str,node,newnode;
    for (var i=0; i<mmlnode.length; i++)
      if (document.createElementNS!=null)
        mmlnode[i].parentNode.replaceChild(convertMath(mmlnode[i]),mmlnode[i]);
      else { // convert for IE
        str = "";
        node = mmlnode[i];
        while (node.nodeName!="/MATH") {
          st = node.nodeName.toLowerCase();
          if (st=="#text") str += node.nodeValue;
          else {
            str += (st.slice(0,1)=="/" ? "</m:"+st.slice(1) : "<m:"+st);
            if (st.slice(0,1)!="/") 
               for(var j=0; j < node.attributes.length; j++)
                 if (node.attributes[j].nodeValue!="italic" &&
                   node.attributes[j].nodeValue!="" &&
                   node.attributes[j].nodeValue!="inherit" &&
                   node.attributes[j].nodeValue!=undefined)
                   str += " "+node.attributes[j].nodeName+"="+
                       "\""+node.attributes[j].nodeValue+"\"";
            str += ">";
          }
          node = node.nextSibling;
          node.parentNode.removeChild(node.previousSibling);
        }
        str += "</m:math>";
        newnode = document.createElement("span");
        node.parentNode.replaceChild(newnode,node);
        newnode.innerHTML = str;
      }
  }
  
  if (document.createElementNS==null) {
    document.write("<object id=\"mathplayer\"\
    classid=\"clsid:32F66A20-7614-11D4-BD11-00104BD3F987\"></object>");
    document.write("<?import namespace=\"m\" implementation=\"#mathplayer\"?>");
  }
  if(typeof window.addEventListener != 'undefined'){
    window.addEventListener('load', convert, false);
  }
  if(typeof window.attachEvent != 'undefined') {
    window.attachEvent('onload', convert);
  }
  /**/
  </script>
</head>
<body>
<h1 id="spatial-analysis-lab">Spatial analysis lab</h1>
<ul>
<li><a href="http://web1.sph.emory.edu/users/lwaller/ch9index.htm">data sets etc.</a> from Waller and Gotway, <em>Applied Spatial Statistics for Public Health Data</em></li>
<li>another <a href="http://labs.bio.unc.edu/Buckley/documents/AnselinIntroSpatRegres.pdf">intro to spatial regression</a></li>
</ul>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(nlme)         ## geostatistical model fitting
<span class="kw">library</span>(RandomFields) ## simulating Gaussian random fields
<span class="kw">library</span>(spdep)        ## SAR/CAR
<span class="kw">library</span>(foreign)      ## for read.dbf
<span class="kw">library</span>(spatstat)     ## point processes
<span class="kw">library</span>(deldir)       ## Delaunay/Dirichlet/Voronoi
<span class="kw">library</span>(ggplot2); <span class="kw">theme_set</span>(<span class="kw">theme_bw</span>())</code></pre>
<h2 id="simulating-spatial-data">Simulating spatial data</h2>
<p>Being able to simulate spatial data is an important component of learning to understand spatial data, as well as a good testing ground for trying out methods. In order to simulate data, we have to decide on:</p>
<ul>
<li><strong>distribution of sample points</strong> (located on an even grid, or on line transects, or irregularly spaced: irregular samples may be completely spatially random, or follow some specified spatial point process, or be specified according to some real set of map coordinates)</li>
<li><strong>trend model</strong>, if any; the simplest case is a linear (<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>x</mi></mrow></math>-<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>y</mi></mrow></math>) trend, or polynomial, or ...</li>
<li>spatial distribution and dependence on <strong>covariates</strong>;</li>
<li><strong>spatial autocorrelation structure</strong> (we'll use the <code>RandomFields</code> package)</li>
<li><strong>conditional distribution</strong>, if not Normal.</li>
</ul>
<p>This is a <em>lot</em> of choices to make, but in less artificial situations your choices will be much more constrained by the question you're asking and what you know about your biological system.</p>
<h2 id="distribution-of-sample-points">Distribution of sample points</h2>
<p>Your sample points might be on an evenly spaced grid, e.g.</p>
<pre class="sourceCode r"><code class="sourceCode r">dx &lt;-<span class="st"> </span>dy &lt;-<span class="st"> </span><span class="fl">0.5</span>           ## grid spacing
xmax &lt;-<span class="st"> </span>ymax &lt;-<span class="st"> </span><span class="dv">10</span>        ## grid max (could also set ymin)
xvec &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>,xmax,<span class="dt">by=</span>dx)
yvec &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>,ymax,<span class="dt">by=</span>dy)
ddgrid &lt;-<span class="st"> </span><span class="kw">expand.grid</span>(<span class="dt">x=</span>xvec,<span class="dt">y=</span>yvec)  ## all x*y combinations
<span class="kw">plot</span>(y~x,<span class="dt">data=</span>ddgrid)                 ## pretty boring!</code></pre>
<p>Alternatively, you might want to completely spatially random (CSR) sample points: you can do this by sampling <code>x</code> and <code>y</code> uniformly over the sample space.</p>
<pre class="sourceCode r"><code class="sourceCode r">npts &lt;-<span class="st"> </span><span class="dv">100</span>
dd &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">x=</span><span class="kw">runif</span>(npts,<span class="dt">max=</span>xmax),
                 <span class="dt">y=</span><span class="kw">runif</span>(npts,<span class="dt">max=</span>ymax))
<span class="kw">plot</span>(y~x,<span class="dt">data=</span>dd,<span class="dt">xlim=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">10</span>),<span class="dt">ylim=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">10</span>))</code></pre>
<p>One last possibility is to simulate the sampling points from a more complex spatial point process. There are many different point process models, some regularly spaced (i.e. &quot;self-avoiding&quot;, &quot;underdispersed&quot;, or more even than CSR) and some clustered (&quot;contagious&quot;, &quot;overdispersed&quot;). We'll try the <em>Strauss</em> process, which simulates evenly spaced points: the parameters are <code>beta</code> (density of points), <code>r</code> (radius of avoidance), and <code>gamma</code> (strength of avoidance: <code>gamma==1</code> means no avoidance, or a CSR process, while <code>gamma==0</code> gives a <em>hard core</em> process where points can never fall within distance <code>r</code> of each other).</p>
<pre class="sourceCode r"><code class="sourceCode r">mod01 &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">cif=</span><span class="st">&quot;strauss&quot;</span>,       ## specify point process; see ?rStrauss
              <span class="dt">par=</span><span class="kw">list</span>(<span class="dt">beta=</span><span class="dv">2</span>,     ## intensity (average density)
                       <span class="dt">gamma=</span><span class="fl">0.2</span>,  ## strength of avoidance
                       <span class="dt">r=</span><span class="fl">0.7</span>),     ## radius of avoidance
              <span class="dt">w=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">10</span>,<span class="dv">0</span>,<span class="dv">10</span>))      ## square window; x={0,10}, y={0,10}
mm &lt;-<span class="st"> </span><span class="kw">rmh</span>(<span class="dt">model=</span>mod01,
          <span class="dt">start=</span><span class="kw">list</span>(<span class="dt">n.start=</span><span class="dv">200</span>), ## starting number of points
          <span class="dt">control=</span><span class="kw">list</span>(<span class="dt">nrep=</span><span class="dv">5000</span>),   ## number of stoch iterations
          <span class="dt">verbose=</span><span class="ot">FALSE</span>)
dd &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">x=</span>mm$x,<span class="dt">y=</span>mm$y)
<span class="kw">plot</span>(y~x,<span class="dt">data=</span>dd,<span class="dt">xlim=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">10</span>),<span class="dt">ylim=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">10</span>))</code></pre>
<p>If you like, experiment with the parameters of the Strauss process ...</p>
<p><strong>advanced/challenge topic</strong> If you want to your sampling area to be an <em>irregular</em> polygon, e.g. you want randomly spaced points within North America, use the <code>sp</code> package to load in polygon data from a shapefile or other map data and use the <code>spsample</code> or <code>makegrid</code> functions.</p>
<h2 id="trend-model">Trend model</h2>
<p>Now that you've picked your sample points, you can specify a spatial trend (if any). This is probably the easiest part of the problem; for a simple linear trend you just have to decide on slopes in the <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>x</mi></mrow></math> and <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>y</mi></mrow></math> directions, e.g.</p>
<pre class="sourceCode r"><code class="sourceCode r">tpars &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">int=</span><span class="dv">1</span>,<span class="dt">x=</span><span class="dv">2</span>,<span class="dt">y=</span><span class="dv">4</span>)  ## trend parameters
dd &lt;-<span class="st"> </span><span class="kw">transform</span>(dd,<span class="dt">r0=</span>tpars$int +<span class="st"> </span>tpars$x*x+tpars$y*y)</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(dd,<span class="kw">aes</span>(x,y,<span class="dt">colour=</span>r0))+<span class="kw">geom_point</span>(<span class="dt">size=</span><span class="dv">4</span>)</code></pre>
<ul>
<li>Try using <code>size</code> as an aesthetic rather than colour, or in addition to colour (you'll have to take out the explicit <code>size=4</code> specification in <code>geom_point</code>); what do you think makes it easier to see the pattern?</li>
<li>Try breaking the <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>y</mi></mrow></math> axis into intervals (<code>dd$xcat &lt;- cut_interval(dd$x,5)</code>) and plotting a lines for each category:</li>
</ul>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(dd,<span class="kw">aes</span>(y,r0,<span class="dt">colour=</span>xcat))+<span class="kw">geom_line</span>()</code></pre>
<p>(<em>lots</em> more possibilities here, e.g. use <code>geom_point()+geom_smooth(method=&quot;lm&quot;,se=FALSE)</code> to get linear regression lines for each <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>x</mi></mrow></math>-category)</p>
<p>It's not too hard to see that this is regular, but of course it's <em>much</em> easier if we are looking at data on a grid:</p>
<pre class="sourceCode r"><code class="sourceCode r">ddgrid &lt;-<span class="st"> </span><span class="kw">transform</span>(ddgrid,<span class="dt">r0=</span>tpars$int +<span class="st"> </span>tpars$x*x+tpars$y*y)
<span class="kw">ggplot</span>(ddgrid,<span class="kw">aes</span>(x,y,<span class="dt">fill=</span>r0))+<span class="kw">geom_tile</span>()</code></pre>
<p><strong>advanced/challenge topic</strong> Interpolating data from an irregular sample is a non-trivial task. Kriging is one possibility (see <code>krige</code> in the <code>sp</code> package), but that requires you to fit a geostatistical model in the first place. Probably the easiest method is to use <code>interpp</code> from the <code>akima</code> package; see if you can create an image (<code>geom_tile()</code>) plot from the interpolated data.</p>
<h2 id="covariates">Covariates</h2>
<p>To keep things a tiny bit simpler, I'm going to assume that our covariate doesn't have any spatial pattern. Once we learn (in the next section) how to generate spatially autocorrelated values, we could make our covariates spatially autocorrelated too ...</p>
<p>Assume precipitation is Normally distributed with some parameters that won't make it go negative ...</p>
<pre class="sourceCode r"><code class="sourceCode r">dd$precip &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="kw">nrow</span>(dd),<span class="dt">mean=</span><span class="dv">8</span>,<span class="dt">sd=</span><span class="dv">2</span>)
dd$r1 &lt;-<span class="st"> </span>dd$r0 +<span class="st"> </span><span class="fl">1.5</span>*dd$precip  ## effect of covariate on response</code></pre>
<h2 id="autocorrelation-structure">Autocorrelation structure</h2>
<p>Here's the interesting bit.</p>
<p>First we set up a spatial autocorrelation model: a Gaussian spatial autocorrelation (i.e. the correlation falls off with distance <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>r</mi></mrow></math> as <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>C</mi><mo stretchy="false">(</mo><mi>r</mi><mo stretchy="false">)</mo><mo>=</mo><mi>exp</mi><mo stretchy="false">(</mo><mo>−</mo><mo stretchy="false">(</mo><mi>r</mi><mo>/</mo><mi>s</mi><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo stretchy="false">)</mo></mrow></math>) with scale (<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>s</mi></mrow></math>) equal to 1.5 and variance 4, along with a nugget variance of 0.5 (you can also add a trend here with <code>RMtrend</code>):</p>
<pre class="sourceCode r"><code class="sourceCode r">m &lt;-<span class="st"> </span><span class="kw">RMgauss</span>(<span class="dt">var=</span><span class="dv">4</span>, <span class="dt">scale=</span><span class="fl">1.5</span>)+<span class="kw">RMnugget</span>(<span class="dt">var=</span><span class="fl">0.5</span>)
ss &lt;-<span class="st"> </span><span class="kw">RFsimulate</span>(m,<span class="dt">x=</span>dd$x,<span class="dt">y=</span>dd$y)  ## ignore message you get here ...
<span class="kw">plot</span>(ss)</code></pre>
<p>(If you want to use <code>RFsimulate</code> for gridded data such as <code>ddgrid</code>, you should specify <code>grid=TRUE</code> to make it much more efficient.)</p>
<p>Extract the values from <code>ss</code> and add them to what we've got so far:</p>
<pre class="sourceCode r"><code class="sourceCode r">dd$r2 &lt;-<span class="st"> </span>dd$r1 +<span class="st"> </span>ss@data$variable1</code></pre>
<h2 id="conditional-distribution">Conditional distribution</h2>
<p>Now suppose we wanted the data to be Poisson distributed rather than Normal. The standard way to do this is to start with values like those we've generated and transform them appropriately so they can be mean values of a Poisson. In particular, we would generally use a <em>log link</em> (or an <em>exponential inverse-link</em> model): if what we've computed so far is <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>η</mi></mrow></math>, we'd use <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>y</mi><mo>∼</mo><mtext mathvariant="normal">Poisson</mtext><mo stretchy="false">(</mo><mi>exp</mi><mo stretchy="false">(</mo><mi>η</mi><mo stretchy="false">)</mo></mrow></math>. (For binary or binomial response we'd use a logit or probit link.) The only problem here is that the actual range of the data we've generated so far (about 7-70) is a bit ridiculous for exponentiating, so we'll scale it down:</p>
<pre class="sourceCode r"><code class="sourceCode r">dd$r3 &lt;-<span class="st"> </span><span class="kw">rpois</span>(<span class="kw">nrow</span>(dd),dd$r2/<span class="dv">10</span>)</code></pre>
<p>The pattern we have now is much more irregular -- practically speaking, we've buried our original trend in noise:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(dd,<span class="kw">aes</span>(x,y,<span class="dt">colour=</span>r3))+<span class="kw">geom_point</span>(<span class="dt">size=</span><span class="dv">4</span>)</code></pre>
<p>We've also added so much noise that the precipitation signal is not particularly clear:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(dd,<span class="kw">aes</span>(precip,r3))+<span class="kw">geom_point</span>()+
<span class="st">    </span><span class="kw">geom_smooth</span>(<span class="dt">method=</span><span class="st">&quot;glm&quot;</span>,<span class="dt">family=</span>poisson)</code></pre>
<p>The <code>RandomFields</code> has an (obsolete) <code>Variogram()</code> function, which interferes with <code>nlme</code>'s function of the same name, so we'll unload the package ...</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">detach</span>(<span class="st">&quot;package:RandomFields&quot;</span>)</code></pre>
<h2 id="constructing-weight-matrices">Constructing weight matrices</h2>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(spdep)</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">nyfile &lt;-<span class="st"> </span><span class="kw">system.file</span>(<span class="st">&quot;etc/misc/nydata.dbf&quot;</span>, <span class="dt">package=</span><span class="st">&quot;spdep&quot;</span>)
nydata0 &lt;-<span class="st"> </span><span class="kw">read.dbf</span>(nyfile)  ## from the foreign package</code></pre>
<p>Use <code>head</code> or <code>View</code> (or RStudio's data viewer) to look at the resulting data. Check out <code>?nydata</code> for more explanation of the data set.</p>
<p>To use the data we have to specify which columns of the data frame contain the spatial coordinates:</p>
<pre class="sourceCode r"><code class="sourceCode r">nydata &lt;-<span class="st"> </span>nydata0  ## make a copy to turn into a 'sp' object
<span class="kw">coordinates</span>(nydata) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;X&quot;</span>, <span class="st">&quot;Y&quot;</span>)  ## set coordinates
nycoord &lt;-<span class="st"> </span><span class="kw">coordinates</span>(nydata)      ## retrieve coordinates
## or: nycoord &lt;- nydata[,c(&quot;X&quot;,&quot;Y&quot;)] *before* setting coordinates(nydata)</code></pre>
<p>Take a preliminary look at the data, coding the number of cases by size and the exposure by colour:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(nydata0,<span class="kw">aes</span>(<span class="dt">x=</span>X,<span class="dt">y=</span>Y,<span class="dt">size=</span>PROPCAS,<span class="dt">colour=</span>PEXPOSURE))+
<span class="st">       </span><span class="kw">geom_point</span>(<span class="dt">alpha=</span><span class="fl">0.5</span>)</code></pre>
<p>The &quot;neighbour-list&quot; (<code>nb</code>) and &quot;weight list&quot; (<code>listw</code>) structures are the basic components that we need in order to do basic weight-matrix operations (compute Moran's I, do simultaneous or conditional autoregressions ...)</p>
<p><strong>Optional</strong> You can explore the available functions for converting to and from these neighbour-lists and weight-lists, and doing things with them:</p>
<pre class="sourceCode r"><code class="sourceCode r">## use regular expressions! ^='beginning of line', $='end of line'
<span class="kw">apropos</span>(<span class="st">&quot;(^nb2|2nb$)&quot;</span>)       ## convert to or from neighbour-lists
<span class="kw">apropos</span>(<span class="st">&quot;(^listw2|2listw$)&quot;</span>) ## convert to or from weight-lists
<span class="kw">methods</span>(<span class="dt">class=</span><span class="st">&quot;nb&quot;</span>)          ## methods for neighbour-lists
<span class="kw">methods</span>(<span class="dt">class=</span><span class="st">&quot;listw&quot;</span>)       ## methods for weight-lists</code></pre>
<p>Construct a Delaunay tesselation graph of nearest neighbors.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(deldir)
nynb &lt;-<span class="st"> </span><span class="kw">tri2nb</span>(nycoord)  ## convert X,Y coordinates to a neighbour list
                         ## via Delaunay triangulation</code></pre>
<p>(Ignore the warning messages.)</p>
<p>To plot a neighbour-list object, you need to specify the object as well as a set of coordinates for the nodes of the graph:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(nynb,nycoord)       ## plot the resulting neighbour-graph</code></pre>
<p>Try computing a weight matrix based on a distance threshold instead:</p>
<pre class="sourceCode r"><code class="sourceCode r">nymat2 &lt;-<span class="st"> </span><span class="kw">as.matrix</span>(<span class="kw">dist</span>(nycoord))&lt;<span class="dv">20</span>
nymat2[] &lt;-<span class="st"> </span><span class="kw">as.numeric</span>(nymat2) ## convert without losing matrix structure
## note 'dist' can also use alternative distance metrics such as 'manhattan'
listw_NY &lt;-<span class="st"> </span><span class="kw">mat2listw</span>(nymat2)  ## convert matrix to weight list
<span class="kw">plot</span>(listw_NY,nycoord,<span class="dt">col=</span><span class="kw">adjustcolor</span>(<span class="st">&quot;black&quot;</span>,<span class="dt">alpha=</span><span class="fl">0.5</span>))</code></pre>
<p>You can also use a pre-computed adjacency matrix:</p>
<pre class="sourceCode r"><code class="sourceCode r">nyadjfile &lt;-<span class="st"> </span><span class="kw">system.file</span>(<span class="st">&quot;etc/misc/nyadjwts.dbf&quot;</span>,<span class="dt">package=</span><span class="st">&quot;spdep&quot;</span>)
nyadjdat &lt;-<span class="st"> </span><span class="kw">read.dbf</span>(nyadjfile)</code></pre>
<p>(Ignore all the messages generated because R is trying to make the fields unique ...)</p>
<p>If you try <code>image(nyadjmat,col=0:1)</code> you'll see that spatial areas are <em>not</em> self-neighbours (the diagonal is blank), but they are arranged in an order so that areas are mostly neighbours with other areas that are close to them in the list (most of the filled-in squares are near the diagonal).</p>
<p>The first column of <code>nyadjdat</code> is an ID column; drop it and convert the data frame to a matrix, and check that the IDs derived from <code>nyadjdat</code> are the same as the IDs in <code>nydata</code>:</p>
<pre class="sourceCode r"><code class="sourceCode r">nyadjmat &lt;-<span class="st"> </span><span class="kw">as.matrix</span>(nyadjdat[,-<span class="dv">1</span>]) ## first column is an ID variable
ID &lt;-<span class="st"> </span><span class="kw">names</span>(nyadjdat)[-<span class="dv">1</span>]
## check that area keys and IDs are the same ...
<span class="kw">identical</span>(<span class="kw">substring</span>(ID, <span class="dv">2</span>, <span class="dv">10</span>), <span class="kw">substring</span>(<span class="kw">as.character</span>(nydata$AREAKEY), <span class="dv">2</span>, <span class="dv">10</span>))</code></pre>
<pre><code>## [1] TRUE</code></pre>
<p>Convert the matrix to a weight list, and add the weights list to the neighbour list we already set up (<code>style=&quot;B&quot;</code> is a simple binary coding; there are other options for standardizing the weights by column or by row).</p>
<pre class="sourceCode r"><code class="sourceCode r">nyadjlw &lt;-<span class="st"> </span><span class="kw">mat2listw</span>(nyadjmat, ID)
<span class="kw">summary</span>(nyadjlw)
listw_NY &lt;-<span class="st"> </span><span class="kw">nb2listw</span>(nyadjlw$neighbours, <span class="dt">style=</span><span class="st">&quot;B&quot;</span>)
<span class="kw">plot</span>(listw_NY,nycoord)</code></pre>
<p>Now we're (almost) ready to try some spatial analysis! First, take a quick look at the association between exposure and number of cases, without worrying about spatial autocorrelation:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(nydata0,
       <span class="kw">aes</span>(<span class="dt">x=</span>PEXPOSURE,<span class="dt">y=</span>PROPCAS))+
<span class="st">    </span><span class="kw">ylim</span>(<span class="dv">0</span>,<span class="fl">0.003</span>)+<span class="st">  </span>## restrict y-axis (omits one value at 0.007)
<span class="st">    </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">size=</span>POP8),<span class="dt">alpha=</span><span class="fl">0.5</span>)+
<span class="st">    </span><span class="kw">geom_smooth</span>(<span class="kw">aes</span>(<span class="dt">weight=</span>POP8),<span class="dt">method=</span><span class="st">&quot;loess&quot;</span>)</code></pre>
<p>Looks like a linear regression might be reasonable.</p>
<p>Fit a linear model weighted by population size:</p>
<pre class="sourceCode r"><code class="sourceCode r">lm1 &lt;-<span class="st"> </span><span class="kw">lm</span>(PROPCAS~PEXPOSURE,<span class="dt">weights=</span>POP8,<span class="dt">data=</span>nydata0)
<span class="kw">summary</span>(lm1)</code></pre>
<p><strong>Finally</strong> we can test Moran's <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>I</mi></mrow></math> on the residuals -- we can (just barely) reject the</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">lm.morantest</span>(lm1,listw_NY)  ## reject null (just ...)</code></pre>
<pre><code>## 
##  Global Moran's I for regression residuals
## 
## data:  
## model: lm(formula = PROPCAS ~ PEXPOSURE, data = nydata0, weights =
## POP8)
## weights: listw_NY
## 
## Moran I statistic standard deviate = 1.685, p-value = 0.046
## alternative hypothesis: greater
## sample estimates:
## Observed Moran's I        Expectation           Variance 
##           0.053705          -0.006257           0.001266</code></pre>
<p>See also <code>?lm.LMtests</code> and <code>?moran.test</code></p>
<p>What about a graphical examination of residuals?</p>
<p><code>fortify(lm1)</code> produces a data frame that contains the data used in the linear regression, plus useful auxiliary information like the residuals (<code>.resid</code>): we need to add the spatial coordinates of the points too:</p>
<pre class="sourceCode r"><code class="sourceCode r">lm1Fort &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="kw">fortify</span>(lm1),
                   <span class="kw">subset</span>(nydata0,<span class="dt">select=</span><span class="kw">c</span>(X,Y)))</code></pre>
<p>Plot residuals in space with size proportional to magnitude, negative residuals in blue and positive residuals in red:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(lm1Fort,<span class="kw">aes</span>(<span class="dt">x=</span>X,<span class="dt">y=</span>Y))+
<span class="st">    </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">size=</span><span class="kw">abs</span>(.resid),
                   <span class="dt">colour=</span>(.resid&gt;<span class="dv">0</span>)),<span class="dt">alpha=</span><span class="fl">0.3</span>)+
<span class="st">    </span><span class="kw">scale_colour_manual</span>(<span class="dt">values=</span><span class="kw">c</span>(<span class="st">&quot;blue&quot;</span>,<span class="st">&quot;red&quot;</span>))+
<span class="st">    </span><span class="kw">scale_size</span>(<span class="dt">range=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">7</span>))  ## make points a little bigger</code></pre>
<ul>
<li>It's a bit hard to distinguish the clustering of the points themselves from a consideration of whether the residuals are autocorrelated in space ...</li>
<li>The big residual near (X=-15,Y=40) is Syracuse (<code>nydata0[which.max(lm1Fort$.resid),]</code>: we should really do some non-spatial diagnostic plots first to find out what's going on ...</li>
</ul>
<p>Finally, we can fit a spatial autoregressive model. There are two possibilities in <code>spdep</code>, <code>?lagsarlm</code> and <code>?errorsarlm</code>; to be honest, I don't understand the difference. In order to make the fit work well, we need to scale the variables:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(<span class="kw">lagsarlm</span>(<span class="kw">scale</span>(PROPCAS)~<span class="kw">scale</span>(PEXPOSURE),<span class="dt">data=</span>nydata0,<span class="dt">listw=</span>listw_NY))</code></pre>
<p>The effect of exposure is still significant (shame on me), but much weaker (<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo>≈</mo><mn>0</mn><mo>.</mo><mn>01</mn></mrow></math> rather <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo>≈</mo><msup><mn>10</mn><mrow><mo>−</mo><mn>5</mn></mrow></msup></mrow></math>).</p>
<h2 id="geostatistical">Geostatistical</h2>
<p><strong>WARNING</strong>: there's still quite a bit about this example that I don't understand as well as I'd like to.</p>
<p>A <em>quick</em> geostatistical fitting example with the <code>Wheat2</code> data set from <code>nlme</code> ... described in more detail in Pinheiro and Bates 2000 (<a href="http://books.google.ca/books?id=3TVDAAAAQBAJ&amp;lpg=PA260&amp;dq=wheat2%20lme&amp;pg=PA261#v=onepage&amp;q=wheat2%20lme&amp;f=false">Google books link</a>)</p>
<p>Do a basic fit (as suggested by P&amp;B):</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(nlme)
g1 &lt;-<span class="st"> </span><span class="kw">gls</span>(yield~variety<span class="dv">-1</span>,<span class="dt">data=</span>Wheat2,<span class="dt">method=</span><span class="st">&quot;ML&quot;</span>)</code></pre>
<p>(Use maximum likelihood instead of restricted maximum likelihood -- this is necessary if you want to compare models with different fixed effects (i.e. test hypotheses about fixed effects), and seems to make the stuff below behave better ...</p>
<p>Compute and plot the variogram of the residuals:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(<span class="kw">Variogram</span>(g1,<span class="dt">form=</span>~latitude+longitude))</code></pre>
<p>The variogram doesn't seem to saturate at all, suggesting the data are <em>non-stationary</em> -- we ought to try fitting a trend model:</p>
<pre class="sourceCode r"><code class="sourceCode r">g2 &lt;-<span class="st"> </span><span class="kw">update</span>(g1,.~.+latitude+longitude)
<span class="kw">plot</span>(<span class="kw">Variogram</span>(g2,<span class="dt">form=</span>~latitude+longitude,<span class="dt">maxDist=</span><span class="dv">32</span>))</code></pre>
<p>Now it seems to peak around 20. We fit a &quot;spherical&quot; correlation model, putting in our initial guess of a scale=20 and a nugget effect of 0.5:</p>
<pre class="sourceCode r"><code class="sourceCode r">g3 &lt;-<span class="st"> </span><span class="kw">update</span>(g2,<span class="dt">correlation=</span><span class="kw">corSpher</span>(<span class="kw">c</span>(<span class="dv">20</span>,<span class="fl">0.5</span>),
                <span class="dt">form=</span>~latitude+longitude,<span class="dt">nugget=</span><span class="ot">TRUE</span>))
## purple = smooth (nonparametric) line, blue = model fit
<span class="kw">plot</span>(<span class="kw">Variogram</span>(g3),<span class="dt">xlim=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">35</span>),
     <span class="dt">smooth=</span><span class="ot">TRUE</span>,<span class="dt">showModel=</span><span class="ot">TRUE</span>,<span class="dt">ylim=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">2</span>))</code></pre>
<p>If we want to see what the variogram looks like <em>with the geostatistical model taken into account</em>, we use <code>resType=&quot;normalized&quot;</code> instead of the default (<code>&quot;pearson&quot;</code>, which controls for heteroscedasticity but not autocorrelation).</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(<span class="kw">Variogram</span>(g3,<span class="dt">resType=</span><span class="st">&quot;normalized&quot;</span>),<span class="dt">ylim=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">2</span>))</code></pre>
<p>This looks flat, which is good ...</p>
<div class="references">

</div>
</body>
</html>
